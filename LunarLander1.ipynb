{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G8fvRUPauGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cc941b-06e8-4181-b02d-e623678dac8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (1,446 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt install swig cmake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aL6g8Kuavgs"
      },
      "outputs": [],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit1/requirements-unit1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8G-wAZha2BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0265beeb-75f7-490a-bc33-2f7b726f1458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [48.6 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,326 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,599 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,046 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,305 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,247 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,153 kB]\n",
            "Fetched 8,976 kB in 3s (3,182 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libglu1-mesa\n",
            "Suggested packages:\n",
            "  libgle3 python3-numpy\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 libglu1-mesa python3-opengl\n",
            "0 upgraded, 3 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 824 kB of archives.\n",
            "After this operation, 8,092 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n",
            "Fetched 824 kB in 1s (644 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 122411 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package python3-opengl.\n",
            "Preparing to unpack .../python3-opengl_3.1.5+dfsg-1_all.deb ...\n",
            "Unpacking python3-opengl (3.1.5+dfsg-1) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up python3-opengl (3.1.5+dfsg-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.5 [28.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.5 [863 kB]\n",
            "Fetched 7,813 kB in 2s (4,471 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 125495 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.5_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.5_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y python3-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9A9Xi9Da10H",
        "outputId": "5f154608-476a-4142-9f10-d462a27ebdab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7a1d10cc8a00>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5H3a887hbVoa"
      },
      "outputs": [],
      "source": [
        "import gymnasium\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub\n",
        "from huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbdq9OGT8TU_",
        "outputId": "58c7532d-9054-432b-bda3-3bff434766ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.0 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyoSLDDRYxon"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "env = gym.make(\n",
        "    \"LunarLander-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evU25iQiZLYK"
      },
      "outputs": [],
      "source": [
        "observation, info = env.reset()\n",
        "\n",
        "for i in range(20):\n",
        "    act = env.action_space.sample()\n",
        "    print(\"action\", act)\n",
        "    observation, reward, terminated, truncated, info = env.step(act)\n",
        "    print(observation)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        print(\"end of episode\")\n",
        "        observation, info = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaSXWKRtcjdZ",
        "outputId": "b61ef038-dc33-4c78-d08d-04dbcab2201e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space Shape (8,)\n",
            "Sample observation [59.639988   37.057953    3.4962835   0.68605524  2.7010477   0.26490086\n",
            "  0.19917868  0.58365136]\n"
          ]
        }
      ],
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "print(\"Observation Space Shape\", env.observation_space.shape)\n",
        "print(\"Sample observation\", env.observation_space.sample())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRzh2tG-djs2"
      },
      "outputs": [],
      "source": [
        "env_id = \"LunarLander-v2\"\n",
        "vec_env = make_vec_env(env_id, n_envs = 16)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Optuna additions\n",
        "import optuna\n",
        "from optuna.pruners import MedianPruner\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
        "training_budget = 4000\n",
        "# Tried with budget = 4k and got -218 reward and then you can try 10x the budget and see any performance gain\n",
        "# I tried 40000 budget and got reward = -418 SO its very random I see, tuning hyperparams > more imp than budget\n"
      ],
      "metadata": {
        "id": "tbKwXY7K_YFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Config\n",
        "N_TRIALS = 50  # Maximum number of trials\n",
        "N_JOBS = 1 # Number of jobs to run in parallel\n",
        "N_STARTUP_TRIALS = 5  # Stop random sampling after N_STARTUP_TRIALS\n",
        "N_EVALUATIONS = 2  # Number of evaluations during the training\n",
        "N_TIMESTEPS = int(1e5)  # Training budget\n",
        "EVAL_FREQ = int(N_TIMESTEPS / N_EVALUATIONS)\n",
        "N_EVAL_ENVS = 5\n",
        "N_EVAL_EPISODES = 100\n",
        "TIMEOUT = int(60 * 5 * 60)  # 3 hours\n",
        "ENV_ID = \"LunarLander-v2\"\n",
        "\n",
        "DEFAULT_HYPERPARAMS = {\n",
        "    \"policy\": \"MlpPolicy\",\n",
        "    \"env\": ENV_ID,\n",
        "}"
      ],
      "metadata": {
        "id": "lrSBRa0NGoRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feade2a8-eab0-4209-e2fc-e243c9d8e362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def sample_a2c_params(trial: optuna.Trial) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sampler for A2C hyperparameters.\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: The sampled hyperparameters for the given trial.\n",
        "    \"\"\"\n",
        "    # Discount factor between 0.9 and 0.9999\n",
        "    gamma = 1.0 - trial.suggest_float(\"gamma\", 0.0001, 0.1, log=True)\n",
        "    max_grad_norm = trial.suggest_float(\"max_grad_norm\", 0.3, 5.0, log=True)\n",
        "    # 8, 16, 32, ... 1024\n",
        "    n_steps = 2 ** trial.suggest_int(\"exponent_n_steps\", 3, 10)\n",
        "\n",
        "    learning_rate =  trial.suggest_float(\"lr\", 1e-5, 1, log=True)\n",
        "    net_arch = trial.suggest_categorical(\"net_arch\" , [\"tiny\", \"small\"])\n",
        "    activation_fn = trial.suggest_categorical(\"activation_fn\" , [\"tanh\", \"relu\"])\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    # Display true values\n",
        "    trial.set_user_attr(\"gamma_\", gamma)\n",
        "    trial.set_user_attr(\"n_steps\", n_steps)\n",
        "\n",
        "    net_arch = [\n",
        "        {\"pi\": [64], \"vf\": [64]}\n",
        "        if net_arch == \"tiny\"\n",
        "        else {\"pi\": [64, 64], \"vf\": [64, 64]}\n",
        "    ]\n",
        "\n",
        "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU}[activation_fn]\n",
        "\n",
        "    return {\n",
        "        \"n_steps\": n_steps,\n",
        "        \"gamma\": gamma,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"max_grad_norm\": max_grad_norm,\n",
        "        \"policy_kwargs\": {\n",
        "            \"net_arch\": net_arch,\n",
        "            \"activation_fn\": activation_fn,\n",
        "        },\n",
        "    }\n",
        "\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "class TrialEvalCallback(EvalCallback):\n",
        "    \"\"\"\n",
        "    Callback used for evaluating and reporting a trial.\n",
        "\n",
        "    :param eval_env: Evaluation environement\n",
        "    :param trial: Optuna trial object\n",
        "    :param n_eval_episodes: Number of evaluation episodes\n",
        "    :param eval_freq:   Evaluate the agent every ``eval_freq`` call of the callback.\n",
        "    :param deterministic: Whether the evaluation should\n",
        "        use a stochastic or deterministic policy.\n",
        "    :param verbose:\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        eval_env: gym.Env,\n",
        "        trial: optuna.Trial,\n",
        "        n_eval_episodes: int = 5,\n",
        "        eval_freq: int = 10000,\n",
        "        deterministic: bool = True,\n",
        "        verbose: int = 0,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            eval_env=eval_env,\n",
        "            n_eval_episodes=n_eval_episodes,\n",
        "            eval_freq=eval_freq,\n",
        "            deterministic=deterministic,\n",
        "            verbose=verbose,\n",
        "        )\n",
        "        self.trial = trial\n",
        "        self.eval_idx = 0\n",
        "        self.is_pruned = False\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0:\n",
        "            # Evaluate policy (done in the parent class)\n",
        "            super()._on_step()\n",
        "            self.eval_idx += 1\n",
        "            # Send report to Optuna\n",
        "            self.trial.report(self.last_mean_reward, self.eval_idx)\n",
        "            # Prune trial if need\n",
        "            if self.trial.should_prune():\n",
        "                self.is_pruned = True\n",
        "                return False\n",
        "        return True"
      ],
      "metadata": {
        "id": "8INvHhx9G8R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial: optuna.Trial) -> float:\n",
        "    \"\"\"\n",
        "    Objective function using by Optuna to evaluate\n",
        "    one configuration (i.e., one set of hyperparameters).\n",
        "\n",
        "    Given a trial object, it will sample hyperparameters,\n",
        "    evaluate it and report the result (mean episodic reward after training)\n",
        "\n",
        "    :param trial: Optuna trial object\n",
        "    :return: Mean episodic reward after training\n",
        "    \"\"\"\n",
        "\n",
        "    kwargs = DEFAULT_HYPERPARAMS.copy()\n",
        "    ### YOUR CODE HERE\n",
        "    # TODO:\n",
        "    # 1. Sample hyperparameters and update the default keyword arguments: `kwargs.update(other_params)`\n",
        "    # 2. Create the evaluation envs\n",
        "    # 3. Create the `TrialEvalCallback`\n",
        "\n",
        "    # 1. Sample hyperparameters and update the keyword arguments\n",
        "    other_params = sample_a2c_params(trial)\n",
        "    kwargs.update(other_params)\n",
        "\n",
        "    # Create the RL model\n",
        "    model = PPO(**kwargs)\n",
        "\n",
        "    # 2. Create envs used for evaluation using `make_vec_env`, `ENV_ID` and `N_EVAL_ENVS`\n",
        "    eval_envs = make_vec_env(ENV_ID, N_EVAL_ENVS)\n",
        "    # 3. Create the `TrialEvalCallback` callback defined above that will periodically evaluate\n",
        "    # and report the performance using `N_EVAL_EPISODES` every `EVAL_FREQ`\n",
        "    # TrialEvalCallback signature:\n",
        "    # TrialEvalCallback(eval_env, trial, n_eval_episodes, eval_freq, deterministic, verbose)\n",
        "    eval_callback = TrialEvalCallback(eval_envs, trial, N_EVAL_EPISODES, EVAL_FREQ, deterministic=True, verbose=0)\n",
        "\n",
        "    ### END OF YOUR CODE\n",
        "\n",
        "    nan_encountered = False\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.learn(N_TIMESTEPS, callback=eval_callback)\n",
        "    except AssertionError as e:\n",
        "        # Sometimes, random hyperparams can generate NaN\n",
        "        print(e)\n",
        "        nan_encountered = True\n",
        "    finally:\n",
        "        # Free memory\n",
        "        model.env.close()\n",
        "        eval_envs.close()\n",
        "\n",
        "    # Tell the optimizer that the trial failed\n",
        "    if nan_encountered:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    if eval_callback.is_pruned:\n",
        "        raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return eval_callback.last_mean_reward"
      ],
      "metadata": {
        "id": "8P5d0NTYHOjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OPTIMIZATION LOOP\n"
      ],
      "metadata": {
        "id": "J8ROlYH_JSv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as th\n",
        "\n",
        "# Set pytorch num threads to 1 for faster training\n",
        "th.set_num_threads(1)\n",
        "# Select the sampler, can be random, TPESampler, CMAES, ...\n",
        "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
        "# Do not prune before 1/3 of the max budget is used\n",
        "pruner = MedianPruner(\n",
        "    n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=N_EVALUATIONS // 3\n",
        ")\n",
        "# Create the study and start the hyperparameter optimization\n",
        "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
        "\n",
        "try:\n",
        "    study.optimize(objective, n_trials=N_TRIALS, n_jobs=N_JOBS, timeout=TIMEOUT)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "print(\"Number of finished trials: \", len(study.trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(f\"  Value: {trial.value}\")\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "print(\"  User attrs:\")\n",
        "for key, value in trial.user_attrs.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "# Write report\n",
        "study.trials_dataframe().to_csv(\"study_results_a2c_cartpole.csv\")\n",
        "\n",
        "fig1 = plot_optimization_history(study)\n",
        "fig2 = plot_param_importances(study)\n",
        "\n",
        "fig1.show()\n",
        "fig2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5zvcSpgJRHJ",
        "outputId": "1b8ea972-a28c-41ca-b0cf-4bbf13357a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-12-24 11:02:59,588] A new study created in memory with name: no-name-83e9227b-ed61-439f-a19e-d9f3d1620d78\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "[I 2023-12-24 11:07:28,353] Trial 0 finished with value: -1195.468079 and parameters: {'gamma': 0.00029303900365385867, 'max_grad_norm': 0.3077157274911906, 'exponent_n_steps': 8, 'lr': 1.8600833950447657e-05, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 0 with value: -1195.468079.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "[I 2023-12-24 11:11:39,823] Trial 1 finished with value: -738.5413224 and parameters: {'gamma': 0.001170205444238357, 'max_grad_norm': 0.83530251608505, 'exponent_n_steps': 9, 'lr': 0.7426094086191593, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -738.5413224.\n",
            "[I 2023-12-24 11:19:14,253] Trial 2 finished with value: -57.9205451 and parameters: {'gamma': 0.04830023176456223, 'max_grad_norm': 3.4720933074125973, 'exponent_n_steps': 7, 'lr': 0.005050201350924233, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 2 with value: -57.9205451.\n",
            "[I 2023-12-24 11:24:25,087] Trial 3 finished with value: 31.320025029999993 and parameters: {'gamma': 0.0044816456080296095, 'max_grad_norm': 4.368406972806647, 'exponent_n_steps': 8, 'lr': 0.01135248557711135, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 31.320025029999993.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 8`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 8\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=8 and n_envs=1)\n",
            "  warnings.warn(\n",
            "[I 2023-12-24 11:41:37,310] Trial 4 finished with value: -432.02252155 and parameters: {'gamma': 0.0008614556677749411, 'max_grad_norm': 4.012013984099744, 'exponent_n_steps': 3, 'lr': 1.176791459392662e-05, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 3 with value: 31.320025029999993.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 16`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=16 and n_envs=1)\n",
            "  warnings.warn(\n",
            "[I 2023-12-24 11:53:36,385] Trial 5 finished with value: -90.45792919 and parameters: {'gamma': 0.021111035893275867, 'max_grad_norm': 1.7536808676151199, 'exponent_n_steps': 4, 'lr': 0.012119615325188916, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 31.320025029999993.\n",
            "[I 2023-12-24 11:55:28,904] Trial 6 pruned. \n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 32`, after every 0 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=32 and n_envs=1)\n",
            "  warnings.warn(\n",
            "[I 2023-12-24 12:02:55,339] Trial 7 finished with value: 2.398430589999998 and parameters: {'gamma': 0.00010416597182229393, 'max_grad_norm': 4.998559871919632, 'exponent_n_steps': 5, 'lr': 0.0003429631296358673, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 3 with value: 31.320025029999993.\n",
            "[I 2023-12-24 12:05:08,284] Trial 8 pruned. \n",
            "[I 2023-12-24 12:16:48,370] Trial 9 pruned. \n",
            "[I 2023-12-24 12:26:48,679] Trial 10 finished with value: -41.560642900000005 and parameters: {'gamma': 0.015585003656349674, 'max_grad_norm': 0.438955016188199, 'exponent_n_steps': 10, 'lr': 0.0005620238974273985, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 3 with value: 31.320025029999993.\n",
            "[I 2023-12-24 12:33:19,876] Trial 11 finished with value: 32.65623275 and parameters: {'gamma': 0.00023615326657169304, 'max_grad_norm': 4.852814089125411, 'exponent_n_steps': 5, 'lr': 0.00038010880769074717, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 11 with value: 32.65623275.\n",
            "[I 2023-12-24 12:35:48,076] Trial 12 pruned. \n",
            "[I 2023-12-24 12:45:13,238] Trial 13 finished with value: -21.365486400000005 and parameters: {'gamma': 0.002976033855538145, 'max_grad_norm': 2.203692844557351, 'exponent_n_steps': 5, 'lr': 0.002371195229070292, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 11 with value: 32.65623275.\n",
            "[I 2023-12-24 12:47:24,557] Trial 14 pruned. \n",
            "[I 2023-12-24 13:00:40,431] Trial 15 finished with value: 166.49806095000002 and parameters: {'gamma': 0.00010687034920069393, 'max_grad_norm': 1.3569182991527136, 'exponent_n_steps': 3, 'lr': 0.002222404284816227, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: 166.49806095000002.\n",
            "[I 2023-12-24 13:08:25,651] Trial 16 pruned. \n",
            "[I 2023-12-24 13:17:50,232] Trial 17 finished with value: 24.79376868 and parameters: {'gamma': 0.0003169172276712521, 'max_grad_norm': 1.1826585936964387, 'exponent_n_steps': 4, 'lr': 0.0018205504101195384, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: 166.49806095000002.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_model = PPO(\"MlpPolicy\", env_id, seed=0, verbose=0).learn(training_budget)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(ppo_model, vec_env, n_eval_episodes=100, deterministic=True)\n",
        "\n",
        "print(f\"PPO Mean episode reward: {mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "-vfZvbYk-Tyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_old = {\n",
        "    \"gamma\": 0.999,\n",
        "    \"n_epochs\": 4,\n",
        "    \"n_steps\": 1024,\n",
        "    \"gae_lambda\": 0.98,\n",
        "    \"vf_coef\": 0.5,\n",
        "    \"normalize_advantage\":True,\n",
        "    \"ent_coef\": 0.01,\n",
        "}"
      ],
      "metadata": {
        "id": "lUWUdXckAmjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUs40K-Weg6A"
      },
      "outputs": [],
      "source": [
        "# The config I tried initially\n",
        "model = PPO(\"MlpPolicy\", vec_env, verbose=1, seed = 10, **params_old, device=\"cuda\")\n",
        "model.learn(total_timesteps=int(1e6))\n",
        "model.save(\"ppo_lunar\")\n",
        "\n",
        "# del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkLBfDbbkdRk"
      },
      "outputs": [],
      "source": [
        "model = PPO.load(\"ppo_lunar\", env=vec_env)\n",
        "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic = True)\n",
        "print(mean_reward, std_reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpTuMJFOzBqJ"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD6Qu02R0heR"
      },
      "outputs": [],
      "source": [
        "!apt-get install python-opengl -y\n",
        "\n",
        "!apt install xvfb -y\n",
        "\n",
        "!pip install pyvirtualdisplay\n",
        "\n",
        "!pip install piglet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDRyr9120nGy"
      },
      "outputs": [],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5qlHzT_x39c"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"LunarLander-v2\", render_mode = \"rgb_array\")\n",
        "obs = env.reset()\n",
        "# prev_screen = env.render(mode = \"rgb_array\")\n",
        "# plt.imshow(np.array(prev_screen[0]))\n",
        "\n",
        "img = plt.imshow(env.render('rgb_array')[0])\n",
        "for i in range(1000):\n",
        "    action, state_= model.predict(obs, deterministic = True)\n",
        "    obs, reward, done, info =  env.step(action)\n",
        "    img.set_data(env.render('rgb_array')[0])\n",
        "    display.display(plt.gcf())\n",
        "    display.clear_output(wait=True)\n",
        "    # env.render(\"human\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUny_4C_64SL"
      },
      "outputs": [],
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcuSVUtR6cAY"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from huggingface_sb3 import package_to_hub\n",
        "\n",
        "# PLACE the variables you've just defined two cells above\n",
        "# Define the name of the environment\n",
        "env_id = \"LunarLander-v2\"\n",
        "model_name = \"ppo_lunar\"\n",
        "\n",
        "# TODO: Define the model architecture we used\n",
        "model_architecture = \"PPO\"\n",
        "\n",
        "## Define a repo_id\n",
        "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "## CHANGE WITH YOUR REPO ID\n",
        "repo_id = \"Swadine/ppo-LunarLander-v2-2\" # Change with your repo id, you can't push with mine 😄\n",
        "\n",
        "## Define the commit message\n",
        "commit_message = \"Upload PPO LunarLander-v2 trained agent\"\n",
        "\n",
        "# Create the evaluation env and set the render_mode=\"rgb_array\"\n",
        "eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
        "\n",
        "# PLACE the package_to_hub function you've just filled here\n",
        "package_to_hub(model=model, # Our trained model\n",
        "               model_name=model_name, # The name of our trained model\n",
        "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
        "               env_id=env_id, # Name of the environment\n",
        "               eval_env=eval_env, # Evaluation Environment\n",
        "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "               commit_message=commit_message)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLS4bum6697h"
      },
      "outputs": [],
      "source": [
        "!pip install shimmy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lygxkQW7MWY"
      },
      "outputs": [],
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "repo_id = \"Swadine/ppo-LunarLander-v2-2\" # The repo_id\n",
        "filename = \"ppo_lunar.zip\" # The model filename.zip\n",
        "\n",
        "# When the model was trained on Python 3.8 the pickle protocol is 5\n",
        "# But Python 3.6, 3.7 use protocol 4\n",
        "# In order to get compatibility we need to:\n",
        "# 1. Install pickle5 (we done it at the beginning of the colab)\n",
        "# 2. Create a custom empty object we pass as parameter to PPO.load()\n",
        "custom_objects = {\n",
        "            \"learning_rate\": 0.0,\n",
        "            \"lr_schedule\": lambda _: 0.0,\n",
        "            \"clip_range\": lambda _: 0.0,\n",
        "}\n",
        "\n",
        "checkpoint = load_from_hub(repo_id, filename)\n",
        "model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp8rrgrR7788"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "eval_env = Monitor(gym.make(\"LunarLander-v2\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}