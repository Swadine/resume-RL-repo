{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning for Trading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:21.897529Z",
     "start_time": "2021-11-16T04:10:21.892603Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:23.441506Z",
     "start_time": "2021-11-16T04:10:21.898569Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from collections import deque\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import gym\n",
    "from gym.envs.registration import register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:24.669692Z",
     "start_time": "2021-11-16T04:10:24.664510Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:24.791466Z",
     "start_time": "2021-11-16T04:10:24.786681Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:25.000425Z",
     "start_time": "2021-11-16T04:10:24.926689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 22:10:24.956597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-15 22:10:24.960919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-15 22:10:24.961256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:25.033871Z",
     "start_time": "2021-11-16T04:10:25.031449Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'trading_bot')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:30.326477Z",
     "start_time": "2021-11-16T04:10:30.324003Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_time(t):\n",
    "    m_, s = divmod(t, 60)\n",
    "    h, m = divmod(m_, 60)\n",
    "    return '{:02.0f}:{:02.0f}:{:02.0f}'.format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:31.011029Z",
     "start_time": "2021-11-16T04:10:31.004868Z"
    }
   },
   "outputs": [],
   "source": [
    "trading_days = 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:31.167371Z",
     "start_time": "2021-11-16T04:10:31.162398Z"
    }
   },
   "outputs": [],
   "source": [
    "register(\n",
    "    id='trading-v0',\n",
    "    entry_point='trading_env:TradingEnvironment',\n",
    "    max_episode_steps=trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:33.062989Z",
     "start_time": "2021-11-16T04:10:33.061026Z"
    }
   },
   "outputs": [],
   "source": [
    "trading_cost_bps = 1e-3\n",
    "time_cost_bps = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:10:33.253407Z",
     "start_time": "2021-11-16T04:10:33.239317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Trading costs: 0.10% | Time costs: 0.01%'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Trading costs: {trading_cost_bps:.2%} | Time costs: {time_cost_bps:.2%}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T04:14:48.346878Z",
     "start_time": "2021-11-16T04:14:46.084768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trading_env:loading data for AAPL...\n",
      "INFO:trading_env:got data for AAPL...\n",
      "INFO:trading_env:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 9367 entries, (Timestamp('1981-01-30 00:00:00'), 'AAPL') to (Timestamp('2018-03-27 00:00:00'), 'AAPL')\n",
      "Data columns (total 10 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   returns  9367 non-null   float64\n",
      " 1   ret_2    9367 non-null   float64\n",
      " 2   ret_5    9367 non-null   float64\n",
      " 3   ret_10   9367 non-null   float64\n",
      " 4   ret_21   9367 non-null   float64\n",
      " 5   rsi      9367 non-null   float64\n",
      " 6   macd     9367 non-null   float64\n",
      " 7   atr      9367 non-null   float64\n",
      " 8   stoch    9367 non-null   float64\n",
      " 9   ultosc   9367 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[42]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trading_environment = gym.make('trading-v0', \n",
    "                               ticker='AAPL',\n",
    "                               trading_days=trading_days,\n",
    "                               trading_cost_bps=trading_cost_bps,\n",
    "                               time_cost_bps=time_cost_bps)\n",
    "trading_environment.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.548145Z",
     "start_time": "2021-02-25T06:20:32.545830Z"
    }
   },
   "outputs": [],
   "source": [
    "state_dim = trading_environment.observation_space.shape[0]\n",
    "num_actions = trading_environment.action_space.n\n",
    "max_episode_steps = trading_environment.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.563692Z",
     "start_time": "2021-02-25T06:20:32.549782Z"
    }
   },
   "outputs": [],
   "source": [
    "class DDQNAgent:\n",
    "    def __init__(self, state_dim,\n",
    "                 num_actions,\n",
    "                 learning_rate,\n",
    "                 gamma,\n",
    "                 epsilon_start,\n",
    "                 epsilon_end,\n",
    "                 epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay,\n",
    "                 replay_capacity,\n",
    "                 architecture,\n",
    "                 l2_reg,\n",
    "                 tau,\n",
    "                 batch_size):\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.num_actions = num_actions\n",
    "        self.experience = deque([], maxlen=replay_capacity)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.architecture = architecture\n",
    "        self.l2_reg = l2_reg\n",
    "\n",
    "        self.online_network = self.build_model()\n",
    "        self.target_network = self.build_model(trainable=False)\n",
    "        self.update_target()\n",
    "\n",
    "        self.epsilon = epsilon_start\n",
    "        self.epsilon_decay_steps = epsilon_decay_steps\n",
    "        self.epsilon_decay = (epsilon_start - epsilon_end) / epsilon_decay_steps\n",
    "        self.epsilon_exponential_decay = epsilon_exponential_decay\n",
    "        self.epsilon_history = []\n",
    "\n",
    "        self.total_steps = self.train_steps = 0\n",
    "        self.episodes = self.episode_length = self.train_episodes = 0\n",
    "        self.steps_per_episode = []\n",
    "        self.episode_reward = 0\n",
    "        self.rewards_history = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.tau = tau\n",
    "        self.losses = []\n",
    "        self.idx = tf.range(batch_size)\n",
    "        self.train = True\n",
    "\n",
    "    def build_model(self, trainable=True):\n",
    "        layers = []\n",
    "        n = len(self.architecture)\n",
    "        for i, units in enumerate(self.architecture, 1):\n",
    "            layers.append(Dense(units=units,\n",
    "                                input_dim=self.state_dim if i == 1 else None,\n",
    "                                activation='relu',\n",
    "                                kernel_regularizer=l2(self.l2_reg),\n",
    "                                name=f'Dense_{i}',\n",
    "                                trainable=trainable))\n",
    "        layers.append(Dropout(.1))\n",
    "        layers.append(Dense(units=self.num_actions,\n",
    "                            trainable=trainable,\n",
    "                            name='Output'))\n",
    "        model = Sequential(layers)\n",
    "        model.compile(loss='mean_squared_error',\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target(self):\n",
    "        self.target_network.set_weights(self.online_network.get_weights())\n",
    "\n",
    "    def epsilon_greedy_policy(self, state):\n",
    "        self.total_steps += 1\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.choice(self.num_actions)\n",
    "        q = self.online_network.predict(state)\n",
    "        return np.argmax(q, axis=1).squeeze()\n",
    "\n",
    "    def memorize_transition(self, s, a, r, s_prime, not_done):\n",
    "        if not_done:\n",
    "            self.episode_reward += r\n",
    "            self.episode_length += 1\n",
    "        else:\n",
    "            if self.train:\n",
    "                if self.episodes < self.epsilon_decay_steps:\n",
    "                    self.epsilon -= self.epsilon_decay\n",
    "                else:\n",
    "                    self.epsilon *= self.epsilon_exponential_decay\n",
    "\n",
    "            self.episodes += 1\n",
    "            self.rewards_history.append(self.episode_reward)\n",
    "            self.steps_per_episode.append(self.episode_length)\n",
    "            self.episode_reward, self.episode_length = 0, 0\n",
    "\n",
    "        self.experience.append((s, a, r, s_prime, not_done))\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if self.batch_size > len(self.experience):\n",
    "            return\n",
    "        minibatch = map(np.array, zip(*sample(self.experience, self.batch_size)))\n",
    "        states, actions, rewards, next_states, not_done = minibatch\n",
    "\n",
    "        next_q_values = self.online_network.predict_on_batch(next_states)\n",
    "        best_actions = tf.argmax(next_q_values, axis=1)\n",
    "\n",
    "        next_q_values_target = self.target_network.predict_on_batch(next_states)\n",
    "        target_q_values = tf.gather_nd(next_q_values_target,\n",
    "                                       tf.stack((self.idx, tf.cast(best_actions, tf.int32)), axis=1))\n",
    "\n",
    "        targets = rewards + not_done * self.gamma * target_q_values\n",
    "\n",
    "        q_values = self.online_network.predict_on_batch(states)\n",
    "        q_values[[self.idx, actions]] = targets\n",
    "\n",
    "        loss = self.online_network.train_on_batch(x=states, y=q_values)\n",
    "        self.losses.append(loss)\n",
    "\n",
    "        if self.total_steps % self.tau == 0:\n",
    "            self.update_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.575368Z",
     "start_time": "2021-02-25T06:20:32.565067Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma = .99,  # discount factor\n",
    "tau = 100  # target network update frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.584925Z",
     "start_time": "2021-02-25T06:20:32.576469Z"
    }
   },
   "outputs": [],
   "source": [
    "architecture = (256, 256)  # units per layer\n",
    "learning_rate = 0.0001  # learning rate\n",
    "l2_reg = 1e-6  # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.593134Z",
     "start_time": "2021-02-25T06:20:32.586645Z"
    }
   },
   "outputs": [],
   "source": [
    "replay_capacity = int(1e6)\n",
    "batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.603464Z",
     "start_time": "2021-02-25T06:20:32.594606Z"
    }
   },
   "outputs": [],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_end = .01\n",
    "epsilon_decay_steps = 250\n",
    "epsilon_exponential_decay = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.613239Z",
     "start_time": "2021-02-25T06:20:32.604766Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.720879Z",
     "start_time": "2021-02-25T06:20:32.614703Z"
    }
   },
   "outputs": [],
   "source": [
    "ddqn = DDQNAgent(state_dim=state_dim,\n",
    "                 num_actions=num_actions,\n",
    "                 learning_rate=learning_rate,\n",
    "                 gamma=gamma,\n",
    "                 epsilon_start=epsilon_start,\n",
    "                 epsilon_end=epsilon_end,\n",
    "                 epsilon_decay_steps=epsilon_decay_steps,\n",
    "                 epsilon_exponential_decay=epsilon_exponential_decay,\n",
    "                 replay_capacity=replay_capacity,\n",
    "                 architecture=architecture,\n",
    "                 l2_reg=l2_reg,\n",
    "                 tau=tau,\n",
    "                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.725896Z",
     "start_time": "2021-02-25T06:20:32.722143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense_1 (Dense)              (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 69,379\n",
      "Trainable params: 69,379\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ddqn.online_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.733088Z",
     "start_time": "2021-02-25T06:20:32.727071Z"
    }
   },
   "outputs": [],
   "source": [
    "total_steps = 0\n",
    "max_episodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.741126Z",
     "start_time": "2021-02-25T06:20:32.734309Z"
    }
   },
   "outputs": [],
   "source": [
    "episode_time, navs, market_navs, diffs, episode_eps = [], [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-25T06:20:32.752721Z",
     "start_time": "2021-02-25T06:20:32.742471Z"
    }
   },
   "outputs": [],
   "source": [
    "def track_results(episode, nav_ma_100, nav_ma_10,\n",
    "                  market_nav_100, market_nav_10,\n",
    "                  win_ratio, total, epsilon):\n",
    "    time_ma = np.mean([episode_time[-100:]])\n",
    "    T = np.sum(episode_time)\n",
    "    \n",
    "    template = '{:>4d} | {} | Agent: {:>6.1%} ({:>6.1%}) | '\n",
    "    template += 'Market: {:>6.1%} ({:>6.1%}) | '\n",
    "    template += 'Wins: {:>5.1%} | eps: {:>6.3f}'\n",
    "    print(template.format(episode, format_time(total), \n",
    "                          nav_ma_100-1, nav_ma_10-1, \n",
    "                          market_nav_100-1, market_nav_10-1, \n",
    "                          win_ratio, epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10 | 00:00:01 | Agent: -39.1% (-39.1%) | Market:   4.6% (  4.6%) | Wins: 20.0% | eps:  0.960\n",
      "  20 | 00:00:51 | Agent: -34.0% (-28.9%) | Market:  23.2% ( 41.8%) | Wins: 20.0% | eps:  0.921\n",
      "  30 | 00:03:02 | Agent: -27.7% (-15.2%) | Market:  20.6% ( 15.4%) | Wins: 16.7% | eps:  0.881\n",
      "  40 | 00:05:11 | Agent: -22.8% ( -8.2%) | Market:  21.2% ( 23.0%) | Wins: 20.0% | eps:  0.842\n",
      "  50 | 00:07:25 | Agent: -21.8% (-17.5%) | Market:  20.2% ( 16.4%) | Wins: 20.0% | eps:  0.802\n",
      "  60 | 00:09:57 | Agent: -22.5% (-26.4%) | Market:  24.5% ( 45.6%) | Wins: 21.7% | eps:  0.762\n",
      "  70 | 00:12:38 | Agent: -20.4% ( -7.5%) | Market:  29.4% ( 59.3%) | Wins: 21.4% | eps:  0.723\n",
      "  80 | 00:15:26 | Agent: -20.9% (-24.7%) | Market:  27.6% ( 14.7%) | Wins: 22.5% | eps:  0.683\n",
      "  90 | 00:18:24 | Agent: -21.1% (-22.2%) | Market:  24.3% ( -2.1%) | Wins: 23.3% | eps:  0.644\n",
      " 100 | 00:21:15 | Agent: -19.5% ( -5.3%) | Market:  24.0% ( 20.9%) | Wins: 23.0% | eps:  0.604\n",
      " 110 | 00:24:16 | Agent: -16.0% ( -4.4%) | Market:  26.0% ( 25.0%) | Wins: 24.0% | eps:  0.564\n",
      " 120 | 00:27:18 | Agent: -10.4% ( 27.0%) | Market:  29.9% ( 80.6%) | Wins: 25.0% | eps:  0.525\n",
      " 130 | 00:30:25 | Agent:  -9.5% ( -5.8%) | Market:  36.4% ( 80.3%) | Wins: 26.0% | eps:  0.485\n",
      " 140 | 00:33:52 | Agent:  -7.8% (  8.6%) | Market:  35.4% ( 13.4%) | Wins: 26.0% | eps:  0.446\n",
      " 150 | 00:37:15 | Agent:  -5.5% (  6.0%) | Market:  37.9% ( 41.0%) | Wins: 28.0% | eps:  0.406\n",
      " 160 | 00:40:44 | Agent:  -4.4% (-15.8%) | Market:  34.9% ( 15.7%) | Wins: 28.0% | eps:  0.366\n",
      " 170 | 00:44:21 | Agent:  -4.7% (-10.8%) | Market:  32.7% ( 37.8%) | Wins: 28.0% | eps:  0.327\n",
      " 180 | 00:47:52 | Agent:  -2.6% ( -2.9%) | Market:  37.6% ( 63.3%) | Wins: 28.0% | eps:  0.287\n",
      " 190 | 00:51:28 | Agent:   0.8% ( 11.2%) | Market:  43.9% ( 61.3%) | Wins: 28.0% | eps:  0.248\n",
      " 200 | 00:55:07 | Agent:  -0.2% (-14.5%) | Market:  43.9% ( 20.4%) | Wins: 28.0% | eps:  0.208\n",
      " 210 | 00:57:39 | Agent:   1.7% ( 14.5%) | Market:  45.1% ( 37.2%) | Wins: 28.0% | eps:  0.168\n",
      " 220 | 01:00:23 | Agent:   0.6% ( 15.3%) | Market:  41.2% ( 41.3%) | Wins: 30.0% | eps:  0.129\n",
      " 230 | 01:03:12 | Agent:   1.4% (  2.2%) | Market:  35.5% ( 24.2%) | Wins: 33.0% | eps:  0.089\n",
      " 240 | 01:06:03 | Agent:   1.5% (  9.4%) | Market:  32.7% (-14.7%) | Wins: 35.0% | eps:  0.050\n",
      " 250 | 01:08:51 | Agent:   0.3% ( -6.2%) | Market:  31.5% ( 28.6%) | Wins: 32.0% | eps:  0.010\n",
      " 260 | 01:11:38 | Agent:   3.6% ( 17.9%) | Market:  33.1% ( 31.6%) | Wins: 34.0% | eps:  0.009\n",
      " 270 | 01:14:24 | Agent:   6.4% ( 17.4%) | Market:  31.5% ( 21.8%) | Wins: 36.0% | eps:  0.008\n",
      " 280 | 01:17:19 | Agent:   8.6% ( 18.6%) | Market:  33.6% ( 84.3%) | Wins: 35.0% | eps:  0.007\n",
      " 290 | 01:20:21 | Agent:   6.9% ( -5.2%) | Market:  28.4% (  9.6%) | Wins: 35.0% | eps:  0.007\n",
      " 300 | 01:23:18 | Agent:  10.1% ( 16.6%) | Market:  31.0% ( 46.1%) | Wins: 36.0% | eps:  0.006\n",
      " 310 | 01:26:13 | Agent:   8.1% ( -4.9%) | Market:  31.0% ( 36.7%) | Wins: 36.0% | eps:  0.005\n",
      " 320 | 01:29:12 | Agent:   7.3% (  7.4%) | Market:  30.9% ( 40.5%) | Wins: 34.0% | eps:  0.005\n",
      " 330 | 01:32:03 | Agent:  10.9% ( 37.6%) | Market:  32.3% ( 38.6%) | Wins: 34.0% | eps:  0.004\n",
      " 340 | 01:34:48 | Agent:  15.3% ( 54.2%) | Market:  41.8% ( 79.7%) | Wins: 33.0% | eps:  0.004\n",
      " 350 | 01:38:07 | Agent:  18.1% ( 21.0%) | Market:  42.4% ( 35.0%) | Wins: 38.0% | eps:  0.004\n",
      " 360 | 01:41:09 | Agent:  20.5% ( 41.9%) | Market:  39.9% (  6.4%) | Wins: 39.0% | eps:  0.003\n",
      " 370 | 01:44:11 | Agent:  21.6% ( 28.7%) | Market:  40.8% ( 30.6%) | Wins: 39.0% | eps:  0.003\n",
      " 380 | 01:47:17 | Agent:  19.6% ( -1.4%) | Market:  39.3% ( 69.3%) | Wins: 40.0% | eps:  0.003\n",
      " 390 | 01:50:20 | Agent:  22.5% ( 23.7%) | Market:  42.6% ( 42.7%) | Wins: 41.0% | eps:  0.002\n",
      " 400 | 01:53:19 | Agent:  22.2% ( 13.9%) | Market:  40.2% ( 22.7%) | Wins: 44.0% | eps:  0.002\n",
      " 410 | 01:57:03 | Agent:  24.5% ( 18.5%) | Market:  42.3% ( 57.8%) | Wins: 44.0% | eps:  0.002\n",
      " 420 | 02:00:58 | Agent:  28.4% ( 45.9%) | Market:  38.6% (  2.7%) | Wins: 48.0% | eps:  0.002\n",
      " 430 | 02:04:21 | Agent:  25.8% ( 11.1%) | Market:  36.7% ( 19.6%) | Wins: 48.0% | eps:  0.002\n",
      " 440 | 02:07:56 | Agent:  25.8% ( 54.4%) | Market:  30.4% ( 17.3%) | Wins: 49.0% | eps:  0.001\n",
      " 450 | 02:11:14 | Agent:  27.4% ( 37.6%) | Market:  31.8% ( 48.6%) | Wins: 46.0% | eps:  0.001\n",
      " 460 | 02:14:15 | Agent:  26.1% ( 28.9%) | Market:  38.0% ( 68.8%) | Wins: 44.0% | eps:  0.001\n",
      " 470 | 02:17:15 | Agent:  27.0% ( 37.6%) | Market:  37.1% ( 21.5%) | Wins: 45.0% | eps:  0.001\n",
      " 480 | 02:20:20 | Agent:  34.1% ( 69.4%) | Market:  35.9% ( 56.9%) | Wins: 48.0% | eps:  0.001\n",
      " 490 | 02:23:17 | Agent:  34.8% ( 30.6%) | Market:  31.6% ( -0.1%) | Wins: 51.0% | eps:  0.001\n",
      " 500 | 02:26:40 | Agent:  36.1% ( 27.3%) | Market:  32.3% ( 29.9%) | Wins: 49.0% | eps:  0.001\n",
      " 510 | 02:30:11 | Agent:  35.4% ( 11.0%) | Market:  30.2% ( 36.8%) | Wins: 49.0% | eps:  0.001\n",
      " 520 | 02:33:49 | Agent:  31.6% (  7.5%) | Market:  32.8% ( 29.0%) | Wins: 46.0% | eps:  0.001\n",
      " 530 | 02:37:32 | Agent:  34.1% ( 36.8%) | Market:  33.1% ( 22.4%) | Wins: 46.0% | eps:  0.001\n",
      " 540 | 02:41:29 | Agent:  35.4% ( 67.0%) | Market:  33.1% ( 17.4%) | Wins: 50.0% | eps:  0.001\n",
      " 550 | 02:45:14 | Agent:  35.4% ( 38.0%) | Market:  33.2% ( 49.0%) | Wins: 51.0% | eps:  0.000\n",
      " 560 | 02:48:50 | Agent:  36.0% ( 35.0%) | Market:  29.9% ( 35.9%) | Wins: 54.0% | eps:  0.000\n",
      " 570 | 02:52:27 | Agent:  36.1% ( 38.4%) | Market:  31.1% ( 34.2%) | Wins: 53.0% | eps:  0.000\n",
      " 580 | 02:56:06 | Agent:  33.4% ( 41.9%) | Market:  33.4% ( 79.9%) | Wins: 50.0% | eps:  0.000\n",
      " 590 | 02:59:44 | Agent:  31.5% ( 12.6%) | Market:  37.0% ( 35.8%) | Wins: 46.0% | eps:  0.000\n",
      " 600 | 03:03:31 | Agent:  31.7% ( 29.3%) | Market:  39.2% ( 51.3%) | Wins: 45.0% | eps:  0.000\n",
      " 610 | 03:07:22 | Agent:  35.1% ( 44.4%) | Market:  38.5% ( 29.6%) | Wins: 50.0% | eps:  0.000\n",
      " 620 | 03:11:15 | Agent:  38.5% ( 42.1%) | Market:  39.6% ( 40.6%) | Wins: 52.0% | eps:  0.000\n",
      " 630 | 03:15:03 | Agent:  36.5% ( 16.7%) | Market:  40.7% ( 33.5%) | Wins: 51.0% | eps:  0.000\n",
      " 640 | 03:18:45 | Agent:  31.8% ( 20.2%) | Market:  44.5% ( 54.8%) | Wins: 44.0% | eps:  0.000\n",
      " 650 | 03:22:24 | Agent:  32.7% ( 46.9%) | Market:  40.2% (  6.4%) | Wins: 47.0% | eps:  0.000\n",
      " 660 | 03:26:06 | Agent:  32.1% ( 28.6%) | Market:  38.9% ( 22.9%) | Wins: 46.0% | eps:  0.000\n",
      " 670 | 03:29:49 | Agent:  29.5% ( 12.3%) | Market:  37.5% ( 20.2%) | Wins: 46.0% | eps:  0.000\n",
      " 680 | 03:33:33 | Agent:  28.3% ( 29.7%) | Market:  31.2% ( 16.4%) | Wins: 50.0% | eps:  0.000\n",
      " 690 | 03:37:19 | Agent:  32.8% ( 57.9%) | Market:  30.5% ( 29.1%) | Wins: 53.0% | eps:  0.000\n",
      " 700 | 03:41:07 | Agent:  32.2% ( 23.2%) | Market:  27.8% ( 24.7%) | Wins: 53.0% | eps:  0.000\n",
      " 710 | 03:44:55 | Agent:  32.2% ( 44.6%) | Market:  25.4% (  5.0%) | Wins: 51.0% | eps:  0.000\n",
      " 720 | 03:48:46 | Agent:  33.6% ( 55.8%) | Market:  25.5% ( 41.7%) | Wins: 49.0% | eps:  0.000\n",
      " 730 | 03:52:39 | Agent:  32.4% (  4.3%) | Market:  26.5% ( 44.2%) | Wins: 51.0% | eps:  0.000\n",
      " 740 | 03:56:31 | Agent:  32.2% ( 18.9%) | Market:  25.7% ( 46.5%) | Wins: 54.0% | eps:  0.000\n",
      " 750 | 04:00:26 | Agent:  28.4% (  8.5%) | Market:  28.4% ( 33.3%) | Wins: 51.0% | eps:  0.000\n",
      " 760 | 04:04:22 | Agent:  26.1% (  5.5%) | Market:  26.9% (  8.3%) | Wins: 52.0% | eps:  0.000\n",
      " 770 | 04:08:19 | Agent:  25.8% (  9.4%) | Market:  28.1% ( 31.9%) | Wins: 51.0% | eps:  0.000\n",
      " 780 | 04:12:19 | Agent:  27.2% ( 44.1%) | Market:  28.0% ( 15.5%) | Wins: 52.0% | eps:  0.000\n",
      " 790 | 04:16:20 | Agent:  24.1% ( 26.4%) | Market:  29.0% ( 38.5%) | Wins: 52.0% | eps:  0.000\n",
      " 800 | 04:20:23 | Agent:  23.8% ( 20.3%) | Market:  29.3% ( 28.1%) | Wins: 53.0% | eps:  0.000\n",
      " 810 | 04:24:27 | Agent:  27.1% ( 77.7%) | Market:  35.6% ( 67.6%) | Wins: 51.0% | eps:  0.000\n",
      " 820 | 04:28:34 | Agent:  24.5% ( 30.3%) | Market:  34.7% ( 33.0%) | Wins: 51.0% | eps:  0.000\n",
      " 830 | 04:32:43 | Agent:  26.3% ( 21.6%) | Market:  30.3% (  0.7%) | Wins: 52.0% | eps:  0.000\n",
      " 840 | 04:36:53 | Agent:  30.3% ( 59.3%) | Market:  26.7% (  9.7%) | Wins: 54.0% | eps:  0.000\n",
      " 850 | 04:41:05 | Agent:  33.6% ( 41.2%) | Market:  26.2% ( 28.5%) | Wins: 54.0% | eps:  0.000\n",
      " 860 | 04:45:20 | Agent:  38.5% ( 55.0%) | Market:  27.7% ( 23.3%) | Wins: 52.0% | eps:  0.000\n",
      " 870 | 04:49:36 | Agent:  42.9% ( 53.4%) | Market:  24.0% ( -4.8%) | Wins: 56.0% | eps:  0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 880 | 04:53:54 | Agent:  48.2% ( 96.8%) | Market:  23.8% ( 13.1%) | Wins: 56.0% | eps:  0.000\n",
      " 890 | 04:58:14 | Agent:  50.0% ( 44.1%) | Market:  22.2% ( 22.3%) | Wins: 56.0% | eps:  0.000\n",
      " 900 | 05:02:35 | Agent:  52.9% ( 49.5%) | Market:  22.0% ( 26.5%) | Wins: 58.0% | eps:  0.000\n",
      " 910 | 05:06:58 | Agent:  52.3% ( 72.1%) | Market:  15.5% (  2.9%) | Wins: 60.0% | eps:  0.000\n",
      " 920 | 05:11:23 | Agent:  53.9% ( 45.7%) | Market:  16.9% ( 46.4%) | Wins: 60.0% | eps:  0.000\n",
      " 930 | 05:15:49 | Agent:  60.2% ( 85.2%) | Market:  15.2% (-16.4%) | Wins: 60.0% | eps:  0.000\n",
      " 940 | 05:20:18 | Agent:  56.8% ( 25.5%) | Market:  15.8% ( 15.7%) | Wins: 60.0% | eps:  0.000\n",
      " 950 | 05:24:51 | Agent:  58.4% ( 56.6%) | Market:  17.2% ( 43.3%) | Wins: 61.0% | eps:  0.000\n",
      " 960 | 05:29:24 | Agent:  57.4% ( 45.0%) | Market:  21.4% ( 65.3%) | Wins: 59.0% | eps:  0.000\n",
      " 970 | 05:33:58 | Agent:  54.2% ( 21.4%) | Market:  22.2% (  2.4%) | Wins: 59.0% | eps:  0.000\n",
      " 980 | 05:38:33 | Agent:  49.7% ( 52.2%) | Market:  22.9% ( 20.5%) | Wins: 57.0% | eps:  0.000\n",
      " 990 | 05:43:11 | Agent:  47.6% ( 22.9%) | Market:  19.9% ( -7.9%) | Wins: 57.0% | eps:  0.000\n",
      "1000 | 05:47:51 | Agent:  46.8% ( 41.5%) | Market:  17.6% (  3.5%) | Wins: 57.0% | eps:  0.000\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "results = []\n",
    "for episode in range(1, max_episodes + 1):\n",
    "    this_state = trading_environment.reset()\n",
    "    for episode_step in range(max_episode_steps):\n",
    "        action = ddqn.epsilon_greedy_policy(this_state.reshape(-1, state_dim))\n",
    "        next_state, reward, done, _ = trading_environment.step(action)\n",
    "    \n",
    "        ddqn.memorize_transition(this_state, \n",
    "                                 action, \n",
    "                                 reward, \n",
    "                                 next_state, \n",
    "                                 0.0 if done else 1.0)\n",
    "        if ddqn.train:\n",
    "            ddqn.experience_replay()\n",
    "        if done:\n",
    "            break\n",
    "        this_state = next_state\n",
    "\n",
    "    # get DataFrame with seqence of actions, returns and nav values\n",
    "    result = trading_environment.env.simulator.result()\n",
    "    \n",
    "    # get results of last step\n",
    "    final = result.iloc[-1]\n",
    "\n",
    "    # apply return (net of cost) of last action to last starting nav \n",
    "    nav = final.nav * (1 + final.strategy_return)\n",
    "    navs.append(nav)\n",
    "\n",
    "    # market nav \n",
    "    market_nav = final.market_nav\n",
    "    market_navs.append(market_nav)\n",
    "\n",
    "    # track difference between agent an market NAV results\n",
    "    diff = nav - market_nav\n",
    "    diffs.append(diff)\n",
    "    \n",
    "    if episode % 10 == 0:\n",
    "        track_results(episode, \n",
    "                      # show mov. average results for 100 (10) periods\n",
    "                      np.mean(navs[-100:]), \n",
    "                      np.mean(navs[-10:]), \n",
    "                      np.mean(market_navs[-100:]), \n",
    "                      np.mean(market_navs[-10:]), \n",
    "                      # share of agent wins, defined as higher ending nav\n",
    "                      np.sum([s > 0 for s in diffs[-100:]])/min(len(diffs), 100), \n",
    "                      time() - start, ddqn.epsilon)\n",
    "    if len(diffs) > 25 and all([r > 0 for r in diffs[-25:]]):\n",
    "        print(result.tail())\n",
    "        break\n",
    "\n",
    "trading_environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 1 to 1000\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Agent              1000 non-null   float64\n",
      " 1   Market             1000 non-null   float64\n",
      " 2   Difference         1000 non-null   float64\n",
      " 3   Strategy Wins (%)  901 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 39.1 KB\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'Episode': list(range(1, episode+1)),\n",
    "                        'Agent': navs,\n",
    "                        'Market': market_navs,\n",
    "                        'Difference': diffs}).set_index('Episode')\n",
    "\n",
    "results['Strategy Wins (%)'] = (results.Difference > 0).rolling(100).sum()\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.023Z"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(results_path / 'results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.025Z"
    }
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    sns.distplot(results.Difference)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 1 to 1000\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Agent              1000 non-null   float64\n",
      " 1   Market             1000 non-null   float64\n",
      " 2   Difference         1000 non-null   float64\n",
      " 3   Strategy Wins (%)  901 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 39.1 KB\n"
     ]
    }
   ],
   "source": [
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-25T06:20:28.031Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14, 4), sharey=True)\n",
    "\n",
    "df1 = (results[['Agent', 'Market']]\n",
    "       .sub(1)\n",
    "       .rolling(100)\n",
    "       .mean())\n",
    "df1.plot(ax=axes[0],\n",
    "         title='Annual Returns (Moving Average)',\n",
    "         lw=1)\n",
    "\n",
    "df2 = results['Strategy Wins (%)'].div(100).rolling(50).mean()\n",
    "df2.plot(ax=axes[1],\n",
    "         title='Agent Outperformance (%, Moving Average)')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        FuncFormatter(lambda x, _: '{:,.0f}'.format(x)))\n",
    "axes[1].axhline(.5, ls='--', c='k', lw=1)\n",
    "\n",
    "sns.despine()\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path / 'performance', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.906px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
